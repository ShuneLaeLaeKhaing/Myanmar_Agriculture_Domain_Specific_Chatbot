import logging
from typing import Optional, Dict
from .hybrid_retriever import HybridRetriever
from .web_search import WebSearcher
from .price_checker import PriceChecker
from .feedback_logger import FeedbackLogger
import time
import re
from typing import List
from rapidfuzz import process, fuzz
import streamlit as st


logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

class ResponseGenerator:
    def __init__(self):
        """Initialize with fallback handling"""
        try:
            @st.cache_resource
            def get_retriever():
                return HybridRetriever("faq.json", "faiss_index")
            self.retriever = get_retriever()
            self.web = WebSearcher()
            self.price_checker = PriceChecker()
            self.min_faq_score = 0.3
            self.feedback_logger = FeedbackLogger()
            logger.info("Response generator ready")
        except Exception as e:
            logger.error(f"Initialization failed: {str(e)}")
            raise
        # Define agriculture-related keywords
        self.agri_keywords = {
                            # General Farming Terms
                            "á€…á€­á€¯á€€á€ºá€•á€»á€­á€¯á€¸á€›á€±á€¸", "á€œá€šá€ºá€šá€¬", "á€œá€šá€ºá€€á€½á€„á€ºá€¸", "á€á€±á€¬á€„á€ºá€šá€¬",
                            "á€€á€»á€±á€¸á€œá€€á€º", "á€€á€»á€±á€¸á€›á€½á€¬", "á€á€±á€¬á€„á€ºá€á€°", "á€œá€šá€ºá€á€™á€¬á€¸",
                            "á€á€±á€¬á€„á€ºá€á€°á€œá€šá€ºá€á€™á€¬á€¸", "á€…á€­á€¯á€€á€ºá€á€„á€ºá€¸", "á€á€¼á€¶", "á€¥á€šá€»á€¬á€‰á€º",

                            # Crop Types (expanded)
                            "á€…á€•á€«á€¸", "á€†á€”á€º", "á€•á€²", "á€•á€²á€á€®á€…á€­á€™á€ºá€¸", "á€•á€²á€…á€‰á€ºá€¸á€„á€¯á€¶", "á€•á€²á€€á€¼á€®á€¸", "á€•á€²á€œá€½á€”á€ºá€¸",
                            "á€€á€¯á€œá€¬á€¸á€•á€²", "á€˜á€­á€¯á€€á€­á€á€ºá€•á€²", "á€•á€¼á€±á€¬á€„á€ºá€¸", "á€”á€¾á€™á€ºá€¸", "á€á€«", "á€€á€¼á€¶", "á€‚á€»á€¯á€¶",
                            "á€Ÿá€„á€ºá€¸á€á€®á€¸á€Ÿá€„á€ºá€¸á€›á€½á€€á€º", "á€á€…á€ºá€á€®á€¸", "á€„á€›á€¯á€á€º", "á€á€›á€™á€ºá€¸", "á€á€á€½á€¬á€¸", "á€–á€›á€²",
                            "á€€á€”á€ºá€…á€½á€”á€ºá€¸", "á€™á€¯á€”á€ºá€œá€¬á€¥", "á€¡á€¬á€œá€°á€¸", "á€€á€¼á€€á€ºá€á€½á€”á€º", "á€™á€á€ºá€•á€²", "á€–á€½á€²á€”á€¯",
                            "á€§á€Šá€·á€ºá€™á€‘á€†á€”á€º", "á€†á€”á€ºá€€á€½á€²", "á€•á€²á€„á€¶á€•á€¼á€¬á€›á€Šá€º", "á€™á€»á€¾á€…á€ºá€á€¼á€±á€¬á€€á€º",

                            # Farming Activities
                            "á€™á€¼á€±á€•á€¼á€¯á€•á€¼á€„á€º", "á€™á€»á€­á€¯á€¸á€…á€­á€•á€º", "á€™á€»á€­á€¯á€¸á€…á€±á€·", "á€•á€»á€­á€¯á€¸á€‘á€±á€¬á€„á€º", "á€•á€»á€­á€¯á€¸á€•á€„á€ºá€¸",
                            "á€•á€±á€«á€„á€ºá€¸á€á€„á€ºá€¸", "á€›á€±á€á€½á€„á€ºá€¸", "á€›á€±á€‘á€¯á€á€º", "á€™á€¼á€±á€†á€®á€©á€‡á€¬",
                            "á€•á€­á€¯á€¸á€á€á€º", "á€•á€±á€«á€„á€ºá€¸á€á€á€º", "á€›á€­á€á€ºá€á€­á€™á€ºá€¸", "á€á€¼á€½á€±á€œá€¾á€±á€·",
                            "á€á€­á€¯á€œá€¾á€±á€¬á€„á€º", "á€¡á€á€¼á€±á€¬á€€á€ºá€œá€¾á€™á€ºá€¸", "á€†á€”á€ºá€…á€€á€º", "á€€á€¼á€­á€á€ºá€á€½á€²",
                            "á€™á€»á€­á€¯á€¸á€€á€±á€¬á€„á€ºá€¸á€›á€½á€±á€¸á€á€»á€šá€º", "á€™á€»á€­á€¯á€¸á€á€”á€·á€ºá€‘á€¯á€á€ºá€œá€¯á€•á€º", "á€“á€¬á€á€ºá€™á€¼á€±á€©á€‡á€¬á€–á€¼á€”á€ºá€¸", "á€¡á€•á€„á€ºá€…á€­á€¯á€…á€½á€á€ºá€™á€¾á€¯á€…á€…á€º",

                            # Livestock & Fisheries
                            "á€™á€½á€±á€¸á€™á€¼á€°á€›á€±á€¸", "á€”á€½á€¬á€¸", "á€€á€»á€½á€²", "á€€á€¼á€€á€º", "á€á€€á€º", "á€†á€­á€á€º",
                            "á€„á€«á€¸", "á€„á€«á€¸á€™á€½á€±á€¸", "á€•á€¯á€…á€½á€”á€º", "á€•á€­á€¯á€¸", "á€•á€­á€¯á€¸á€™á€½á€±á€¸", "á€•á€»á€¬á€¸á€™á€½á€±á€¸",

                            # Tools & Equipment (cleaned)
                            "á€‘á€½á€”á€ºá€…á€€á€º", "á€œá€¾á€Šá€ºá€¸", "á€•á€±á€«á€€á€ºá€•á€¼á€¬á€¸", "á€€á€¯á€á€„á€º", "á€šá€”á€ºá€á€«",
                            "á€–á€­á€”á€•á€º", "á€€á€á€ºá€€á€¼á€±á€¸", "á€•á€±á€«á€„á€ºá€¸á€á€á€ºá€†á€±á€¸", "á€•á€­á€¯á€¸á€á€á€ºá€†á€±á€¸",
                            "á€™á€¼á€±á€©á€‡á€¬", "á€•á€»á€­á€¯á€¸á€˜á€°á€¸", "á€›á€±á€•á€­á€¯á€€á€º", "á€›á€±á€…á€¯á€•á€ºá€…á€€á€º", "á€–á€»á€”á€ºá€¸á€…á€€á€º", "á€á€šá€ºá€šá€°á€•á€­á€¯á€·á€†á€±á€¬á€„á€ºá€™á€¾á€¯",

                            # Natural Factors
                            "á€™á€­á€¯á€¸", "á€”á€±á€•á€°", "á€›á€¬á€á€®á€¥á€á€¯", "á€™á€¼á€±á€†á€®á€œá€½á€¾á€¬", "á€™á€¼á€±á€¡á€™á€»á€­á€¯á€¸á€¡á€…á€¬á€¸",
                            "á€›á€±á€™á€¼á€±", "á€œá€±á€•á€¼á€„á€ºá€¸", "á€›á€±á€€á€¼á€®á€¸", "á€™á€­á€¯á€¸á€á€±á€«á€„á€º", "á€á€²á€€á€”á€¹á€á€¬á€›",

                            # Problems & Solutions
                            "á€•á€­á€¯á€¸á€™á€½á€¾á€¬á€¸", "á€›á€±á€¬á€‚á€«", "á€¡á€•á€„á€ºá€”á€¬", "á€¡á€›á€½á€€á€ºá€œá€­á€•á€º",
                            "á€¡á€™á€¼á€…á€ºá€•á€¯á€•á€º", "á€¡á€á€®á€¸á€€á€½á€²", "á€€á€¬á€€á€½á€šá€ºá€”á€Šá€ºá€¸", "á€€á€¯á€á€”á€Šá€ºá€¸",
                            "á€–á€»á€€á€ºá€•á€­á€¯á€¸", "á€•á€±á€«á€„á€ºá€¸á€•á€„á€ºá€¸", "á€†á€±á€¸á€–á€¼á€”á€ºá€¸", "á€€á€¼á€­á€¯á€á€„á€ºá€€á€¬", "á€”á€Šá€ºá€¸á€œá€™á€ºá€¸á€•á€¼á€±á€¬á€„á€ºá€¸á€œá€²á€™á€¾á€¯",

                            # Economics & Market
                            "á€ˆá€±á€¸á€”á€¾á€¯á€”á€ºá€¸", "á€…á€•á€«á€¸á€ˆá€±á€¸", "á€•á€²á€ˆá€±á€¸", "á€á€®á€¸á€”á€¾á€¶á€ˆá€±á€¸",
                            "á€…á€­á€¯á€€á€ºá€€á€¯á€”á€º", "á€›á€±á€¬á€„á€ºá€¸á€á€šá€ºá€›á€±á€¸", "á€á€»á€±á€¸á€„á€½á€±", "á€¡á€‘á€½á€€á€ºá€”á€¾á€¯á€”á€ºá€¸",
                            "á€á€„á€ºá€„á€½á€±", "á€…á€›á€­á€á€º", "á€¡á€™á€¼á€á€º", "á€ˆá€±á€¸á€€á€½á€€á€º", "á€ˆá€±á€¸á€€á€½á€€á€ºá€á€„á€ºá€á€¼á€„á€ºá€¸",

                            # Government & Organizations
                            "á€…á€­á€¯á€€á€ºá€•á€»á€­á€¯á€¸á€›á€±á€¸á€¦á€¸á€…á€®á€¸", "á€…á€­á€¯á€€á€ºá€•á€»á€­á€¯á€¸á€›á€±á€¸á€Œá€¬á€”", "á€™á€¼á€±á€…á€¬á€›á€„á€ºá€¸",
                            "á€€á€»á€±á€¸á€œá€€á€ºá€–á€½á€¶á€·á€–á€¼á€­á€¯á€¸á€›á€±á€¸", "á€€á€»á€±á€¸á€œá€€á€ºá€˜á€á€º", "á€€á€»á€±á€¸á€œá€€á€ºá€œá€™á€ºá€¸",
                            "á€†á€Šá€ºá€™á€¼á€±á€¬á€„á€ºá€¸", "á€›á€±á€á€½á€šá€º", "á€œá€»á€¾á€•á€ºá€…á€…á€ºá€™á€®á€¸", "á€•á€‹á€­á€Šá€¬á€‰á€º", "á€›á€¯á€¶á€¸á€á€”á€ºá€‘á€™á€ºá€¸",

                            # Traditional Knowledge
                            "á€œá€šá€ºá€šá€¬á€“á€œá€±á€·", "á€†á€±á€¸á€–á€€á€ºá€á€„á€º", "á€á€˜á€¬á€á€†á€±á€¸", "á€”á€€á€¹á€á€á€º",

                            # Modern Techniques & Inputs
                            "á€”á€Šá€ºá€¸á€•á€Šá€¬", "á€¡á€±á€¬á€ºá€‚á€²á€”á€…á€º", "á€‡á€®á€", "á€Ÿá€­á€¯á€€á€ºá€’á€›á€­á€¯á€•á€­á€¯á€”á€…á€º",
                            "á€‚á€»á€®á€¡á€­á€¯á€„á€ºá€¡á€€á€º", "á€’á€®á€¡á€¬á€•á€®", "á€¡á€¬á€†á€„á€ºá€¸á€”á€…á€º", "á€¡á€­á€¯á€„á€ºá€…á€®á€¡á€™á€º",
                            "á€€á€¬á€—á€½á€”á€ºá€á€»á€‘á€¬á€¸á€á€¼á€„á€ºá€¸", "á€™á€¼á€±á€†á€®á€œá€½á€¾á€¬á€…á€…á€º", "á€á€˜á€¬á€á€“á€¬á€á€ºá€™á€¼á€±á€©á€‡á€¬",

                            # Seasonal Terms
                            "á€”á€½á€±á€…á€•á€«á€¸", "á€™á€­á€¯á€¸á€…á€•á€«á€¸", "á€†á€±á€¬á€„á€ºá€¸á€…á€•á€«á€¸", "á€”á€½á€±á€›á€¬á€á€®",
                            "á€™á€­á€¯á€¸á€›á€¬á€á€®", "á€†á€±á€¬á€„á€ºá€¸á€›á€¬á€á€®", "á€€á€°á€¸á€•á€¼á€±á€¬á€„á€ºá€¸", "á€…á€­á€¯á€€á€ºá€›á€¬á€á€®"
                        }

    def _is_agriculture_related(self, text: str) -> bool:
        """Check if text contains agriculture keywords or domains"""
        text_lower = text.lower()
        return (any(keyword in text_lower for keyword in self.agri_keywords))

    def generate_response(self, query: str) -> Dict[str, Optional[str]]:
        """Strict FAQ â†’ Web fallback pipeline"""
        try:
            if not self._is_myanmar(query):
                return {
                    "source": "Language Error",
                    "response": "á€€á€»á€±á€¸á€‡á€°á€¸á€•á€¼á€¯á á€™á€¼á€”á€ºá€™á€¬á€œá€­á€¯ á€™á€±á€¸á€™á€¼á€”á€ºá€¸á€•á€«á‹ (Please ask in Myanmar language)",
                    "confidence": "low"
                }
            
            if not query or len(query.strip()) < 2:
                return self._empty_response()
            
            # Price Checker starts here
            logger.info(f"Original query: {query}")
        
            # More flexible normalization
            normalized_query = query.replace(" ", "").replace("á‹", "").replace("áŠ", "")
            logger.info(f"Normalized query: {normalized_query}")

            found_products = self._find_products_in_query(normalized_query)
            
            # Check for price keywords (more flexible matching)
            price_keywords = ["á€ˆá€±á€¸", "á€ˆá€±á€¸á€”á€¾á€¯á€”á€ºá€¸","á€ˆá€±á€¸á€”á€¾á€¯á€”á€ºá€¸á€á€­á€á€»á€„á€º"]
            price_keyword_found = any(
                kw in normalized_query 
                for kw in price_keywords
            )
            logger.info(f"Price keyword found: {price_keyword_found}")
            
            
            if price_keyword_found and found_products:
                logger.info("Attempting price check...")
                price_start = time.perf_counter()
                price_response = self.price_checker.get_price_response(normalized_query)
                logger.info(f"Price response: {price_response}")
                print(f"Price check took {time.perf_counter() - price_start:.2f} seconds")
                
                if price_response:
                    return {
                        "source": "ğŸ’° Market Price",
                        "response": price_response,
                    }
            
            # Phase 1: FAQ 
            faq_start = time.perf_counter()
            faq_answer = self.retriever.search(
                query, 
                # min_score=self.min_faq_score
            )
            print(faq_answer)
            if faq_answer:
                return {
                    "source": "ğŸ“š FAQ",
                    "response": faq_answer,
                    "confidence": "high"
                }
            
            print(f"FAQ search took {time.perf_counter() - faq_start:.2f} seconds")
            
            if not self._is_agriculture_related(query):
                self.feedback_logger.log_fallback(
                    query=query,
                    fallback_type="non_agricultural",
                    additional_context={"validation_method": "keyword_check"}
                )
                return {
                    "source": "Out of scope",
                    "response": "á€€á€»á€±á€¸á€‡á€°á€¸á€•á€¼á€¯á á€…á€­á€¯á€€á€ºá€•á€»á€­á€¯á€¸á€›á€±á€¸á€”á€¾á€„á€·á€º á€á€€á€ºá€†á€­á€¯á€„á€ºá€á€±á€¬ á€™á€±á€¸á€á€½á€”á€ºá€¸á€™á€»á€¬á€¸á€€á€­á€¯á€á€¬ á€™á€±á€¸á€™á€¼á€”á€ºá€¸á€•á€«á‹",
                    "confidence": "low"
                }

            web_start = time.perf_counter()
            web_content = self.web.search(query)
            if  web_content:
                self.feedback_logger.log_fallback(
                    query=query,
                    fallback_type="web_results",
                    additional_context={"search_time": f"{time.perf_counter() - web_start:.2f}s"}
                )
                return {
                    "source": "ğŸŒ Web",
                    "response": web_content,
                    "confidence": "medium"
                }
            print(f"Web search took {time.perf_counter() - web_start:.2f} seconds")
            
            return {
                "source": "Out of scope",
                "response": "///á€€á€»á€±á€¸á€‡á€°á€¸á€•á€¼á€¯á á€…á€­á€¯á€€á€ºá€•á€»á€­á€¯á€¸á€›á€±á€¸á€”á€¾á€„á€·á€º á€á€€á€ºá€†á€­á€¯á€„á€ºá€á€±á€¬ á€™á€±á€¸á€á€½á€”á€ºá€¸á€™á€»á€¬á€¸á€€á€­á€¯á€á€¬ á€™á€±á€¸á€™á€¼á€”á€ºá€¸á€•á€«á‹",
                "confidence": "low"
            }
            
            
        except Exception as e:
            logger.error(f"Response generation failed: {e}")
            return self._error_response()

    

    def _empty_response(self) -> Dict:
        return {
            "source": None,
            "response": "á€€á€»á€±á€¸á€‡á€°á€¸á€•á€¼á€¯á á€•á€­á€¯á€™á€­á€¯á€›á€¾á€„á€ºá€¸á€œá€„á€ºá€¸á€á€±á€¬ á€™á€±á€¸á€á€½á€”á€ºá€¸á€™á€±á€¸á€•á€«",
            "confidence": None
        }

    def _error_response(self) -> Dict:
        return {
            "source": "error",
            "response": "á€á€±á€¬á€„á€ºá€¸á€•á€”á€ºá€•á€«á€á€Šá€ºá‹ á€¡á€–á€¼á€±á€›á€¾á€¬á€›á€”á€º á€™á€¡á€±á€¬á€„á€ºá€™á€¼á€„á€ºá€•á€«",
            "confidence": None
        }
    
    def _is_myanmar(self, text: str) -> bool:
        myanmar_unicode = re.compile(r'[\u1000-\u109F\uAA60-\uAA7F]')
        return bool(myanmar_unicode.search(text))
    

    def _find_products_in_query(self,query: str) -> List[str]:
        """Find all products mentioned in query using fuzzy matching"""
        # Check for products (partial matching)
        product_list = ["á€€á€”á€ºá€…á€½á€”á€ºá€¸á€›á€½á€€á€º","á€€á€¯á€œá€¬á€¸á€•á€²", "á€€á€¯á€œá€¬á€¸á€•á€²(HL)", "á€€á€¯á€œá€¬á€¸á€•á€²(á€™á€¼á€€á€¼á€±á€¸)", "á€€á€¼á€€á€ºá€á€½á€”á€ºá€”á€®", "á€€á€¼á€€á€ºá€á€½á€”á€ºá€–á€¼á€°", "á€€á€¼á€€á€ºá€á€½á€”á€ºá€–á€¼á€°(á€‘á€°á€¸á€„á€«á€¸)", "á€€á€¼á€€á€ºá€á€½á€”á€ºá€–á€¼á€°(á€‘á€°á€¸á€œá€±á€¸)",
                    "á€€á€¼á€€á€ºá€¥", "á€á€›á€™á€ºá€¸á€á€»á€‰á€ºá€á€®á€¸", "á€‚á€±á€«á€ºá€–á€®á€‘á€¯á€•á€º", "á€‚á€»á€„á€ºá€¸","á€‚á€»á€¯á€¶", "á€‚á€»á€¯á€¶á€‘á€½á€€á€ºá€á€­á€¯á€¸", "á€‚á€»á€¯á€¶á€–á€¼á€°á€á€”á€·á€º", "á€„á€›á€¯á€á€ºá€›á€¾á€Šá€º", "á€„á€«á€¸á€€á€¼á€„á€ºá€¸", "á€„á€«á€¸á€€á€¼á€„á€ºá€¸á€–á€¼á€°(á€—á€­á€¯á€€á€ºá€á€½á€²)", "á€„á€«á€¸á€€á€½á€™á€ºá€¸á€›á€¾á€•á€º",
                    "á€„á€«á€¸á€á€¯á€¶á€¸á€™", "á€„á€«á€¸á€’á€”á€º", "á€„á€«á€¸á€”á€¾á€•á€º", "á€„á€«á€¸á€•á€°á€á€„á€ºá€¸", "á€„á€«á€¸á€•á€»á€€á€º", "á€„á€«á€¸â€Œâ€Œâ€Œá€›á€½á€¾á€±á€€á€¼á€®á€¸","á€†á€”á€ºá€€á€½á€² B(1,2)" ,"á€†á€”á€ºá€€á€½á€² B(2,3,4)","á€†á€¬á€¸á€€á€¼á€™á€ºá€¸(á€›á€­á€¯á€¸á€›á€­á€¯á€¸)á€•á€„", "á€†á€¬á€¸á€á€»á€±á€¬", "á€á€®á€œá€¬á€¸á€—á€®á€¸á€œá€¬á€¸", "á€‘á€­á€¯á€„á€ºá€á€™á€º",
                    "á€’á€®á€‡á€šá€ºá€†á€® (á€•á€›á€®á€™á€®á€šá€¶)", "á€”á€±á€€á€¼á€¬á€–á€á€º", "á€”á€¾á€™á€ºá€¸á€†á€®", "á€”á€¾á€™á€ºá€¸á€Šá€­á€¯", "á€”á€¾á€™á€ºá€¸á€”á€®", "á€”á€¾á€™á€ºá€¸á€–á€á€º", "á€•á€œá€¬á€á€°á€¸", "á€•á€œá€¬á€œá€”á€ºá€¸", "á€•á€«á€€á€°á€¸", "á€•á€±á€«á€ºá€†á€”á€ºá€¸á€™á€½á€¾á€±á€¸",
                    "á€•á€²á€€á€¼á€®á€¸", "á€•á€²á€…á€‰á€ºá€¸á€„á€¯á€¶", "á€•á€²á€…á€‰á€ºá€¸á€„á€¯á€¶(á€”á€®)", "á€•á€²á€†á€®","á€•á€²á€á€®á€…á€­á€™á€ºá€¸", "á€•á€²á€á€®á€…á€­á€™á€ºá€¸(á€¡á€á€…á€º)", "á€•á€²á€á€®á€…á€­á€™á€ºá€¸á€€á€¼á€®á€¸", "á€•á€²á€”á€®á€œá€¯á€¶á€¸á€€á€¼á€¬á€¸", "á€•á€²á€–á€á€º", "á€•á€²á€œá€½á€”á€ºá€¸á€–á€¼á€°", "á€–á€½á€²á€”á€¯",
                    "á€˜á€­á€¯á€€á€­á€á€º", "á€˜á€­á€¯á€€á€­á€á€ºá€•á€²", "á€˜á€²á€¥", "á€™á€á€ºá€•á€²", "á€™á€”á€ºá€€á€»á€®á€¸á€á€®á€¸á€™á€¾á€Šá€·á€º", "á€™á€­á€¯á€¸á€€á€¼á€€á€ºá€á€½á€”á€ºá€”á€® (á€¡á€€á€¼á€®á€¸)", "á€™á€­á€¯á€¸á€€á€¼á€€á€ºá€á€½á€”á€ºá€”á€®(á€¡á€á€±á€¸)", "á€™á€¼á€…á€ºá€á€¬á€¸á€€á€¼á€€á€ºá€á€½á€”á€ºá€”á€®(á€¡á€€á€¼á€®á€¸)", "á€™á€¼á€…á€ºá€á€¬á€¸á€€á€¼á€€á€ºá€á€½á€”á€ºá€”á€®(á€¡á€á€±á€¸)", "á€™á€¼á€±á€•á€²",
                    "á€™á€¼á€±á€•á€²á€á€±á€¬á€„á€·á€º", "á€™á€¼á€±á€•á€²á€œá€¯á€¶á€¸á€†á€¶á€”á€®", "á€™á€¼á€±á€•á€²á€œá€¯á€¶á€¸á€†á€¶á€–á€¼á€°", "á€›á€½á€¾á€±á€„á€«á€¸", "á€á€«", "á€á€€á€¼á€¬á€¸á€–á€¼á€°", "á€¡á€¬á€œá€°á€¸", "á€¡á€¬á€œá€°á€¸(á€™á€¼á€”á€ºá€™á€¬á€á€®á€¸)",
                    "á€§á€Šá€·á€ºá€™á€‘á€†á€”á€º(á€™á€”á€±á€¬á€á€¯á€)á€á€…á€º", "á€§á€Šá€·á€ºá€™á€‘á€†á€”á€º(á€™á€”á€±á€¬á€á€¯á€)á€Ÿá€±á€¬á€„á€ºá€¸",]
        normalized_query = query.replace(" ", "").replace("á‹", "").replace("áŠ", "")
        found_products = []
        
        # First check for exact matches
        for product in product_list:
            if product in normalized_query:
                found_products.append(product)
        
        # If no exact matches found, try fuzzy matching
        if not found_products:
            for product in product_list:
                result = process.extractOne(
                    product,
                    [normalized_query],
                    scorer=fuzz.token_set_ratio,
                    score_cutoff=60  # Lower threshold for partial matching
                )
                if result and result[1] >= 60:
                    found_products.append(product)
        
        return list(set(found_products)) 